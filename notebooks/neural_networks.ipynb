{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_networks.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "t5GQ9BUQBqdd",
        "colab_type": "code",
        "outputId": "bff65cb0-e544-46f1-e4d4-49c3a160c0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5bdb8000 @  0x7f40705172a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WpBZS_LyeaMb",
        "colab_type": "code",
        "outputId": "17693f70-fb22-4f13-993f-ea686aedd0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-01 08:55:11--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2813 (2.7K) [text/plain]\n",
            "Saving to: ‘helper.py’\n",
            "\n",
            "\rhelper.py             0%[                    ]       0  --.-KB/s               \rhelper.py           100%[===================>]   2.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-01 08:55:11 (50.7 MB/s) - ‘helper.py’ saved [2813/2813]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a41t5BxiCMUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import imp \n",
        "helper = imp.new_module('helper')\n",
        "exec(open(\"/content/helper.py\").read(), helper.__dict__)\n",
        "\n",
        "import helper\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kIDgc9HGCbRE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('MNIST_data', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PzSMKmJOZ8Nz",
        "colab_type": "code",
        "outputId": "826990f5-5615-4a4b-d4e9-09988e1204c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ppb3csrfZ-j_",
        "colab_type": "code",
        "outputId": "faa005a3-b1a4-4546-d3ff-529fe9d71997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHGZNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f276c9a7208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RbCs1XUvDmMt",
        "colab_type": "code",
        "outputId": "e2cb869d-e7ef-4479-efa7-b2de680909c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "#output\n",
        "torch.manual_seed(9)\n",
        "\n",
        "def activation(x):\n",
        "  return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "# Flatten the input\n",
        "inputs = images.view(images.shape[0], -1)\n",
        "\n",
        "# Create parameters\n",
        "W1 = torch.randn(784, 256)\n",
        "b1 = torch.randn(256)\n",
        "\n",
        "W2 = torch.randn(256, 10)\n",
        "b2 = torch.randn(10)\n",
        "\n",
        "h = activation(torch.mm(inputs, W1) + b1)\n",
        "\n",
        "output = torch.mm(h, W2) + b2\n",
        "output.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "jRD0N_pKJuyn",
        "colab_type": "code",
        "outputId": "275b4b04-0680-4d6e-ad4d-4d56274c31ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "cell_type": "code",
      "source": [
        "# softmax\n",
        "\n",
        "def softmax(x):\n",
        "  return torch.exp(x) / torch.sum(torch.exp(x), dim = 1).view(-1, 1)\n",
        "\n",
        "probabilities = softmax(output)\n",
        "\n",
        "probabilities.sum(dim=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
              "         1.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "85jRk-qfJtet",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Pytorch NN module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zumi_I_4OXJL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PxXSzyqWOZIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    #inputs to hidden layer linear transformation\n",
        "    self.hidden = nn.Linear(784, 256)\n",
        "    # output layer, 10 units\n",
        "    self.output = nn.Linear(256, 10)\n",
        "    \n",
        "    # Define sigmoid activation and softmax\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.sotfmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # pass the input tensor through each operations\n",
        "    x = self.hidden(x)\n",
        "    x = self.sigmoid(x)\n",
        "    x = self.output(x)\n",
        "    x = self.softmax(x)\n",
        "    \n",
        "    return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RyyFbuqQQ8VP",
        "colab_type": "code",
        "outputId": "1c1ba2f6-0073-4ddb-b8d7-ad24e94b6383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "cell_type": "code",
      "source": [
        "model = Network()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (sotfmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "MNLvK1djPQ0Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # inputs to hidden layer transformation\n",
        "    self.hidden = nn.Linear(784, 256)\n",
        "    # output layer, 10 units\n",
        "    self.output = nn.Linear(256, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # hidden layer with sigmoid function\n",
        "    x = F.sigmoid(self.hidden(x))\n",
        "    # output layer with softmax\n",
        "    x = F.softmax(self.output(x), dim = 1)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vwq6KdCkQwRh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}